{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cce35979-0aff-4126-a7fc-3dddaac65df2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=6>ğŸ¥³**æ¬¢è¿ä½“éªŒJupyteräº‘ä¸Šå¼€å‘ç¯å¢ƒ**</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f328b077-0531-4d1a-9c1d-530a043c25ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ä½¿ç”¨é¡»çŸ¥\n",
    "> - ç›®å‰`jupyter`è¿è¡Œæ—¶é•¿é™åˆ¶åªèƒ½è¿è¡Œ2ä¸ªå°æ—¶ã€‚**2ä¸ªå°æ—¶ä¹‹åå°†ä¼šè‡ªåŠ¨é‡Šæ”¾æ‰€æœ‰èµ„æºï¼Œè¯·æå‰å°†æ‰€éœ€èµ„æºä¸‹è½½åˆ°æœ¬åœ°æˆ–git pushåˆ°å¹³å°ä¸­**ã€‚\n",
    "> - æœ¬å¹³å°æ˜¯å¼€æ”¾çš„å­¦ä¹ å¹³å°ï¼Œç¦æ­¢ä½¿ç”¨æœ¬å¹³å°è¿›è¡Œå•†ä¸šç”¨é€”å’Œéæ³•ç”¨é€”æˆ–è€…æ¶æ„æ”»å‡»ï¼Œä¸€æ—¦å‘ç°å°†ä¾æ³•è¿½ç©¶ã€‚\n",
    "\n",
    "æ­¤å¼€å‘ç¯å¢ƒæ˜¯ä½¿ç”¨çš„æ˜¯`Jupyter Lab 3.x`ï¼Œå¹¶é›†æˆäº†å®ç”¨çš„æ’ä»¶ã€‚æ‚¨å¯ä»¥åœ¨`Jupyter Lab`ä¸Šçµæ´»è¿è¡Œè°ƒè¯•ä»£ç å’Œç¼–å†™æ–‡æ¡£ï¼Œ`Jupyter Lab`é›†æˆäº†å¾ˆå¤šç¼–è¾‘å™¨ï¼Œä¾‹å¦‚ `Jupyter` ç¬”è®°æœ¬ã€æ–‡æœ¬ç¼–è¾‘å™¨ã€ç»ˆç«¯å’Œè‡ªå®šä¹‰ç»„ä»¶ã€‚æ›´å¤šçš„è¯¦ç»†ä»‹ç»ä½ å¯ä»¥æŸ¥çœ‹ [JupyterLabå®˜ç½‘æ–‡æ¡£ä»‹ç»](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html#overview)ã€‚\n",
    "    \n",
    "æ¥ä¸‹æ¥è·Ÿæˆ‘æ¥ä¸€èµ·æ²‰æµ¸å¼åœ°æ¢ç´¢`Jupyter Lab`å§â—\n",
    "\n",
    "**è‹¥æ‚¨ä¸ç†Ÿæ‚‰`Jupyter Lab`, æ‚¨å¯ä»¥å…ˆé˜…è¯»`Jupyteræ“ä½œæ–‡æ¡£.inynb`æ–‡ä»¶ç†Ÿæ‚‰`Jupyter`çš„åŸºæœ¬æ“ä½œ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a7f21-9594-4682-bec4-0bb0d7901be8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# å¿«é€Ÿä½“éªŒå¹³å°æ“ä½œ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "433ba222-a423-4f41-8c52-b9e3a248f6a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## å¿«é€Ÿä½“éªŒæ¨ç†\n",
    "å¹³å°é›†æˆäº†[å¤§æ¨¡å‹å¥—ä»¶MindSpore MindFormers](https://gitee.com/mindspore/mindformers/tree/r0.3/)ï¼Œå¯æ”¯æŒä¸‹è½½å’ŒåŠ è½½ç±»Transformerå’ŒSOTAæ¨¡å‹ï¼Œå¹¶æ”¯æŒpipelineæ¨ç†ï¼Œç›®å‰æ”¯æŒtext classifcationã€token classificationã€swinã€vitã€zero shot classificationå’Œquestion answeringç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚\n",
    "æœªæ¥å¹³å°å°†ä¼šé›†æˆMindSpore MindFormersæ›´å¤šçš„ç‰¹æ€§ï¼Œ**MindFormerså…·æœ‰æ›´å¤šçš„ç‰¹æ€§ï¼Œæ¯”å¦‚é¢„è®­ç»ƒã€å¾®è°ƒã€è¯„ä¼°ã€å¤šå¡è®­ç»ƒç­‰ï¼Œå¦‚æœæ„Ÿå…´è¶£å¯ä»¥è¿›å…¥ä¸‹é¢ä»£ç ä»“ï¼Œä¸€é”®ä¸‰è¿å“¦**ã€‚\n",
    "- [MindFormersä»“](https://gitee.com/mindspore/mindformers/tree/r0.3/)\n",
    "- [MindSPoreä»“](https://gitee.com/mindspore/mindspore)\n",
    "\n",
    "**MindFormersä¸‹æ¸¸ä»»åŠ¡ä½“éªŒé“¾æ¥ï¼ˆæŒç»­æ›´æ–°ä¸­ï¼‰**ï¼š\n",
    "- [vit](https://xihe.mindspore.cn/projects/MindSpore/vit_image_classification)\n",
    "- [swin](https://xihe.mindspore.cn/projects/MindSpore/Swin)\n",
    "- [token classification](https://xihe.mindspore.cn/projects/MindSpore/token_classification)\n",
    "- [text classifcation](https://xihe.mindspore.cn/projects/MindSpore/text_classification)\n",
    "- [zero shot classification](https://xihe.mindspore.cn/projects/MindSpore/zero_shot_image_classification)\n",
    "- [question answering](https://xihe.mindspore.cn/projects/MindSpore/question_answering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20014b5-4e4f-4a47-936a-9ec69b828df9",
   "metadata": {
    "tags": []
   },
   "source": [
    "**ä½ å¯ä»¥`Ctrl+Enter`è¿è¡Œä¸‹é¢ä»£ç ï¼Œæˆ–è€…ä½¿ç”¨èœå•æ çš„ä¸‰è§’å½¢è¿è¡Œä¸‹é¢çš„Cellï¼Œæ³¨æ„ä¸€å®šè¦æŒ‰é¡ºåºæ‰§è¡Œã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e432aef0-f8d4-4113-b1c8-6a30ac127000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# è‹¥å‡ºç°ValueError: Failed to read the checkpoint file . May not have permission to read it, please check the correct of the file. è¯·å°†ä¸‹é¢æ³¨é‡Šæ”¾å¼€\n",
    "# !rm checkpoint_download/vit/ -rf\n",
    "from mindformers.pipeline import pipeline\n",
    "from mindformers.tools.image_tools import load_image\n",
    "\n",
    "pipeline_task = pipeline(\"image_classification\", model=\"mindspore/vit_base_p16\")\n",
    "img = load_image(\n",
    "    \"https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png\"\n",
    ")\n",
    "pipeline_result = pipeline_task(img, top_k=3)\n",
    "pipeline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea5f32-6021-43af-af71-9c3890477dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# è‹¥å‡ºç°ValueError: Failed to read the checkpoint file . May not have permission to read it, please check the correct of the file. è¯·å°†ä¸‹é¢æ³¨é‡Šæ”¾å¼€\n",
    "# !rm checkpoint_download/vit/ -rf\n",
    "from mindformers import AutoConfig, AutoTokenizer, BertForTokenClassification\n",
    "from mindformers.dataset.labels import cluener_labels\n",
    "from mindformers.pipeline import TokenClassificationPipeline\n",
    "\n",
    "input_data = [\"è¡¨èº«åˆ»æœ‰ä»£è¡¨æ—¥å†…ç“¦é’Ÿè¡¨åŒ freresoltramareçš„â€œfoâ€å­—æ ·ã€‚\"]\n",
    "\n",
    "id2label = {label_id: label for label_id, label in enumerate(cluener_labels)}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mindspore/tokcls_bert_base_chinese_cluener\",\n",
    ")\n",
    "tokcls_cluener_config = AutoConfig.from_pretrained(\n",
    "    \"mindspore/tokcls_bert_base_chinese_cluener\",\n",
    ")\n",
    "\n",
    "# This is a known issue, you need to specify batch size equal to 1 when creating bert model.\n",
    "tokcls_cluener_config.batch_size = 1\n",
    "\n",
    "model = BertForTokenClassification(tokcls_cluener_config)\n",
    "tokcls_pipeline = TokenClassificationPipeline(\n",
    "    task=\"token_classification\",\n",
    "    model=model,\n",
    "    id2label=id2label,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=model.config.seq_length,\n",
    "    padding=\"max_length\",\n",
    ")\n",
    "\n",
    "results = tokcls_pipeline(input_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e20e3-ab08-46a8-b078-31c21c1d93dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## å¿«é€Ÿä½“éªŒè®­ç»ƒ\n",
    "**è¿™é‡Œä»¥Lenet5å®ç°æ‰‹å†™æ•°å­—ä½“ä¸ºæ¡ˆä¾‹**\n",
    "\n",
    "**åŸºæœ¬ä»‹ç»**\n",
    "\n",
    "LeNetæè¿°\n",
    "LeNetæ˜¯1998å¹´æå‡ºçš„ä¸€ç§å…¸å‹çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚å®ƒè¢«ç”¨äºæ•°å­—è¯†åˆ«å¹¶å–å¾—äº†å·¨å¤§çš„æˆåŠŸã€‚\n",
    "\n",
    "[è®ºæ–‡](https://gitee.com/link?target=https%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F726791)ï¼š Y.Lecun, L.Bottou, Y.Bengio, P.Haffner.Gradient-Based Learning Applied to Document Recognition.Proceedings of the IEEE.1998.\n",
    "\n",
    "**æ¨¡å‹æ¶æ„**\n",
    "\n",
    "LeNetéå¸¸ç®€å•ï¼ŒåŒ…å«5å±‚ï¼Œç”±2ä¸ªå·ç§¯å±‚å’Œ3ä¸ªå…¨è¿æ¥å±‚ç»„æˆã€‚\n",
    "\n",
    "![Lenet5](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/tutorials/source_zh_cn/beginner/images/lenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a44f26-db86-4849-a50a-b7145241624a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "ä¸‹è½½å®Œæˆåï¼Œä¸‹è½½å®Œæˆåçš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š  \n",
    "\n",
    "```\n",
    "â””â”€â”€ lenet_mnist\n",
    "    â”œâ”€â”€ best.ckpt\n",
    "    â”œâ”€â”€ lenet_ascend_v150_mnist_official_cv_acc98.49.ckpt\n",
    "    â”œâ”€â”€ lenet_ascend_v160_mnist_official_cv_acc98.49.ckpt\n",
    "    â”œâ”€â”€ lenet_ascend_v170_mnist_official_cv_acc98.49.ckpt\n",
    "    â”œâ”€â”€ lenet-1_1875.ckpt\n",
    "    â””â”€â”€ README.md\n",
    "```\n",
    "è¿™é‡Œç”¨lenet-1_1875.ckptåšfinetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb42a8b-0798-4609-8149-b33cd41028d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://source-xihe.mindspore.cn/MindSpore/lenet_mnist.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d806ac-4418-4a6f-a14c-681c42edb6b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  ä¸‹è½½MNISTæ•°æ®é›†\n",
    "\n",
    "ä¸‹è½½å®Œæˆåï¼Œä¸‹è½½å®Œæˆåçš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š  \n",
    "```\n",
    "â””â”€â”€ MNIST_Data\n",
    "    â”œâ”€â”€ test # æµ‹è¯•é›†\n",
    "    â”‚   â”œâ”€â”€ t10k-images-idx3-ubyte \n",
    "    â”‚   â””â”€â”€ t10k-labels-idx1-ubyte \n",
    "    â”‚â”€â”€ train # è®­ç»ƒé›†\n",
    "    â”‚    â”œâ”€â”€ train-images-idx3-ubyte\n",
    "    â”‚    â””â”€â”€ train-lables-idx1-ubyte\n",
    "    â””â”€â”€ README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16570322-0191-498c-bfb8-ff6a96c2dbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from download import download\n",
    "\n",
    "url = (\n",
    "    \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\"\n",
    "    \"notebook/datasets/MNIST_Data.zip\"\n",
    ")\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9371f92a-9ff1-47d7-a412-aad573c0f1cb",
   "metadata": {},
   "source": [
    "###  æ‰§è¡Œè®­ç»ƒä»£ç \n",
    "\n",
    "ä»£ç æ¥æºäº[lenet5ä»£ç ä»“](https://xihe.mindspore.cn/projects/MindSpore/lenet5/tree)çš„[train.pyæ–‡ä»¶](https://xihe.mindspore.cn/projects/MindSpore/lenet5/blob/train/train.py)\n",
    "\n",
    "**æ‚¨å¯ä»¥æ‰‹åŠ¨åœ°è°ƒæ•´ä¸‹é¢çš„è¶…å‚æ•°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91215c1a-ddfc-4f11-bbbf-5c74e484e2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\" LeNet training \"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import mindspore\n",
    "from mindspore import load_checkpoint, load_param_into_net, nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint\n",
    "from mindvision.classification.dataset import Mnist\n",
    "from mindvision.classification.models import lenet\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "data_url = \"./MNIST_Data\"\n",
    "pretrain_url = \"lenet_mnist/lenet-1_1875.ckpt\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "# è¶…å‚æ•°è®¾ç½®\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "def train():\n",
    "    # å°†æ¨¡å‹å‚æ•°å­˜å…¥parameterçš„å­—å…¸ä¸­ï¼Œè¿™é‡ŒåŠ è½½çš„æ˜¯ä¸Šé¢è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ¨¡å‹å‚æ•°\n",
    "    param_dict = load_checkpoint(pretrain_url)\n",
    "\n",
    "    # é‡æ–°å®šä¹‰ä¸€ä¸ªLeNetç¥ç»ç½‘ç»œ\n",
    "    network = lenet(num_classes=10, pretrained=False)\n",
    "\n",
    "    # å°†å‚æ•°åŠ è½½åˆ°ç½‘ç»œä¸­\n",
    "    load_param_into_net(network, param_dict)\n",
    "    # å®šä¹‰æŸå¤±å‡½æ•°\n",
    "    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "    # å®šä¹‰ä¼˜åŒ–å™¨å‡½æ•°\n",
    "    net_opt = nn.Momentum(\n",
    "        network.trainable_params(),\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=momentum,\n",
    "    )\n",
    "    model = Model(\n",
    "        network,\n",
    "        loss_fn=net_loss,\n",
    "        optimizer=net_opt,\n",
    "        metrics={\"accuracy\"},\n",
    "    )\n",
    "\n",
    "    # å®šä¹‰è®­ç»ƒæ•°æ®é›†\n",
    "    download_train = Mnist(\n",
    "        path=data_url,\n",
    "        split=\"train\",\n",
    "        batch_size=batch_size,\n",
    "        repeat_num=1,\n",
    "        shuffle=True,\n",
    "        resize=32,\n",
    "        download=True,\n",
    "    )\n",
    "    dataset_train = download_train.run()\n",
    "    # print(len(download_train))\n",
    "    # print(dataset_train.)\n",
    "\n",
    "    # è®¾ç½®æ¨¡å‹ä¿å­˜å‚æ•°\n",
    "    config_ck = CheckpointConfig(\n",
    "        save_checkpoint_steps=int(60000 / batch_size), keep_checkpoint_max=1\n",
    "    )\n",
    "\n",
    "    # åº”ç”¨æ¨¡å‹ä¿å­˜å‚æ•°\n",
    "    check_point = ModelCheckpoint(\n",
    "        prefix=\"lenet\", directory=output_path, config=config_ck\n",
    "    )\n",
    "\n",
    "    # è®­ç»ƒç½‘ç»œæ¨¡å‹\n",
    "    model.train(\n",
    "        num_epochs, dataset_train, callbacks=[check_point, LossMonitor(0.01, 1875)]\n",
    "    )\n",
    "\n",
    "\n",
    "# æ‰§è¡Œè®­ç»ƒ\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c44528-1f27-4c3d-b788-ed8fe4192ca2",
   "metadata": {},
   "source": [
    "## å¿«é€Ÿä½“éªŒæ¨ç†å¯è§†åŒ–\n",
    "å¹³å°é›†æˆ[Gradio](https://www.gradio.app/docs), æ‚¨å¯ä»¥è‡ªå®šä¹‰åº”ç”¨ã€‚ç”±äºå®‰å…¨é—®é¢˜ä½ éœ€è¦å°†`gr.xx.launch(share=True)`çš„`share`è®¾ä¸º`True`ï¼Œå³å¯åœ¨Jupyterä½“éªŒGradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf43a1-8ca6-48f1-9816-e2cf0151c6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from mindspore import Tensor, load_checkpoint, load_param_into_net\n",
    "from mindspore.nn import Softmax\n",
    "from mindspore.train import Model\n",
    "from mindvision.classification.models import lenet\n",
    "\n",
    "NUM_CLASS = 10\n",
    "ckpt_path = \"./lenet_mnist/best.ckpt\"\n",
    "\n",
    "# åŠ è½½ç½‘è·¯\n",
    "# å°†æ¨¡å‹å‚æ•°å­˜å…¥parameterçš„å­—å…¸ä¸­\n",
    "param_dict = load_checkpoint(ckpt_path)\n",
    "\n",
    "# é‡æ–°å®šä¹‰ä¸€ä¸ªLeNetç¥ç»ç½‘ç»œ,æ³¨æ„è¾“å…¥æ˜¯32*32ï¼Œlossé‡‡ç”¨çš„æ˜¯SoftmaxCE\n",
    "network = lenet(num_classes=NUM_CLASS, pretrained=False)\n",
    "# å°†å‚æ•°åŠ è½½åˆ°ç½‘ç»œä¸­\n",
    "load_param_into_net(network, param_dict)\n",
    "model = Model(network)\n",
    "\n",
    "\n",
    "def predict_digit(img):\n",
    "    # å¤„ç†å›¾ç‰‡,è½¬åŒ–ä¸º Nï¼ŒCï¼ŒH,W\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img.astype(np.float32)\n",
    "    img = img / 255\n",
    "    img = img.reshape((1, 1, 32, 32))\n",
    "\n",
    "    # é¢„æµ‹\n",
    "    predict_score = model.predict(Tensor(img)).reshape(-1)\n",
    "    predict_probability = Softmax()(predict_score)\n",
    "\n",
    "    return {str(i): predict_probability[i].asnumpy().item() for i in range(NUM_CLASS)}\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "    fn=predict_digit,\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=gr.outputs.Label(num_top_classes=NUM_CLASS, label=\"é¢„æµ‹ç±»åˆ«\"),\n",
    "    live=False,\n",
    "    css=\".footer {display:none !important}\",\n",
    "    title=\"0-9æ•°å­—ç”»æ¿\",\n",
    "    description=\"ç”»0-9æ•°å­—\",\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e65ffd-5077-4925-aa83-f575079db0c1",
   "metadata": {},
   "source": [
    "## TinyMSç‰ˆæœ¬æ¨ç†\n",
    "TinyMSæ˜¯ä¸€æ¬¾ä¸»è¦ç”¨PyThonè¯­è¨€ç¼–å†™çš„å¼€æºæ·±åº¦å­¦ä¹ å¼€å‘å·¥å…·åŒ…ï¼ŒåŸºäºä»¥MindSporeä¸ºä»£è¡¨çš„æ–°å‹å¼€æºæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæä¾›é¢å‘ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹éƒ¨ç½²å…¨æµç¨‹çš„æç®€æ˜“ç”¨çš„é«˜é˜¶APIå°è£…ï¼Œå¹¶é€šè¿‡æ˜“äºæ‰©å±•çš„æ¨¡å—åŒ–è®¾è®¡ï¼Œæä¾›è¦†ç›–å¤šç§ä¸šåŠ¡åœºæ™¯çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "ç›¸å…³é“¾æ¥\n",
    "- [TinyMSå®˜æ–¹æ–‡æ¡£](https://tinyms.readthedocs.io/en/latest/quickstart/overview.html)\n",
    "- [TinyMSå®˜æ–¹ä»“](https://github.com/tinyms-ai/tinyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1366b-2cc8-4180-8ddb-b751b9a34483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ä½ ä¹Ÿå¯ä»¥é€šè¿‡downloadä¸‹è½½\n",
    "from download import download\n",
    "\n",
    "url = \"https://obs-xihe-beijing4.obs.cn-north-4.myhuaweicloud.com/xihe-img/projects/cloud/5.png\"\n",
    "path = download(url, \"./5.png\", kind=\"file\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c1b2a-81b1-4655-83d2-e0f68067066d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tinyms as ts\n",
    "from mindspore import Tensor\n",
    "from PIL import Image\n",
    "from tinyms.model import Model, lenet5\n",
    "from tinyms.vision import mnist_transform\n",
    "\n",
    "img = Image.open(\"./5.png\")\n",
    "img = mnist_transform(img)\n",
    "\n",
    "net = lenet5(class_num=10)\n",
    "model = Model(net)\n",
    "model.load_checkpoint(\"./lenet_mnist/best.ckpt\")\n",
    "\n",
    "input = ts.expand_dims(ts.Tensor(img), 0)\n",
    "res = model.predict(input).asnumpy()\n",
    "print(\"The label is:\", mnist_transform.postprocess(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2037b1-8798-4e5b-a360-0e8b67b6a991",
   "metadata": {
    "tags": []
   },
   "source": [
    "## æ›´å¤šä½“éªŒæŒç»­æ›´æ–°ä¸­..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
